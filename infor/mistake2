/home/olga/Pictures/my/lib/python3.11/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.
  warnings.warn(
False
PyTorchVideo available: True
Checking files...
Train CSV exists: True
Validation CSV exists: True
Train video directory exists: True
Validation video directory exists: True
Creating train CSV...
Found file: /home/olga/Pictures/Rehab-app/train/PINCH GRIP/PINCH GRIP_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PINCH GRIP/PINCH GRIP_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PINCH GRIP/PINCH GRIP_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PINCH GRIP/PINCH GRIP_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/Y BALANCE/Y BALANCE_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/Y BALANCE/Y BALANCE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/Y BALANCE/Y BALANCE_part4.mp4
Found file: /home/olga/Pictures/Rehab-app/train/Y BALANCE/Y BALANCE_part5.mp4
Found file: /home/olga/Pictures/Rehab-app/train/Y BALANCE/Y BALANCE_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part4.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part6.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part5.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP EXTENSION/TRICEP EXTENSION_part7.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PLANK/PLANK_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PLANK/PLANK_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PLANK/PLANK_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/PLANK/PLANK_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP DIPS/TRICEP DIPS_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TRICEP DIPS/TRICEP DIPS_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/REVERSE LUNGE/REVERSE LUNGE_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/REVERSE LUNGE/REVERSE LUNGE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/REVERSE LUNGE/REVERSE LUNGE_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TREE/TREE_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TREE/TREE_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/TREE/TREE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/HEEL WALKING/HEEL WALKING_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/HEEL WALKING/HEEL WALKING_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/HEEL WALKING/HEEL WALKING_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/HEEL WALKING/HEEL WALKING_part5.mp4
Found file: /home/olga/Pictures/Rehab-app/train/HEEL WALKING/HEEL WALKING_part4.mp4
Found file: /home/olga/Pictures/Rehab-app/train/WAITERS BOW/WAITERS BOW_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/train/WAITERS BOW/WAITERS BOW_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/train/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part3.mp4
Found file: /home/olga/Pictures/Rehab-app/train/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part4.mp4
Found file: /home/olga/Pictures/Rehab-app/train/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part2.mp4
Found file: /home/olga/Pictures/Rehab-app/train/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part1.mp4
Number of videos found: 38
Shape of labels tensor: torch.Size([38, 10])
CSV file created at: /home/olga/Pictures/Rehab-app/train/train.csv
Train CSV shape: (38, 11)

Creating validation CSV...
Found file: /home/olga/Pictures/Rehab-app/val/PINCH GRIP/PINCH GRIP_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/PINCH GRIP/PINCH GRIP_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/Y BALANCE/Y BALANCE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/Y BALANCE/Y BALANCE_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TRICEP EXTENSION/TRICEP EXTENSION_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TRICEP EXTENSION/TRICEP EXTENSION_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/PLANK/PLANK_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/PLANK/PLANK_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TRICEP DIPS/TRICEP DIPS_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TRICEP DIPS/TRICEP DIPS_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/REVERSE LUNGE/REVERSE LUNGE_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/REVERSE LUNGE/REVERSE LUNGE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TREE/TREE_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/TREE/TREE_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/HEEL WALKING/HEEL WALKING_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/HEEL WALKING/HEEL WALKING_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/WAITERS BOW/WAITERS BOW_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/WAITERS BOW/WAITERS BOW_part1.mp4
Found file: /home/olga/Pictures/Rehab-app/val/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part0.mp4
Found file: /home/olga/Pictures/Rehab-app/val/SCAPULA PROTRACTION/SCAPULA PROTRACTION_part1.mp4
Number of videos found: 20
Shape of labels tensor: torch.Size([20, 10])
CSV file created at: /home/olga/Pictures/Rehab-app/val/val.csv
Validation CSV shape: (20, 11)

Checking CSV contents:
Train CSV:
                             video  HEEL WALKING  ...  WAITERS BOW  Y BALANCE
0  PINCH GRIP/PINCH GRIP_part1.mp4             0  ...            0          0
1  PINCH GRIP/PINCH GRIP_part0.mp4             0  ...            0          0
2  PINCH GRIP/PINCH GRIP_part3.mp4             0  ...            0          0
3  PINCH GRIP/PINCH GRIP_part2.mp4             0  ...            0          0
4    Y BALANCE/Y BALANCE_part2.mp4             0  ...            0          1

[5 rows x 11 columns]

Validation CSV:
                                         video  ...  Y BALANCE
0              PINCH GRIP/PINCH GRIP_part1.mp4  ...          0
1              PINCH GRIP/PINCH GRIP_part0.mp4  ...          0
2                Y BALANCE/Y BALANCE_part1.mp4  ...          1
3                Y BALANCE/Y BALANCE_part0.mp4  ...          1
4  TRICEP EXTENSION/TRICEP EXTENSION_part0.mp4  ...          0

[5 rows x 11 columns]
/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/apply_func.py:31: LightningDeprecationWarning: `pytorch_lightning.utilities.apply_func.apply_to_collection` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_utilities.core.apply_func.apply_to_collection` instead.
  rank_zero_deprecation(
Labels: None
Train files: <flash.video.classification.input.VideoClassificationCSVInput object at 0x7f1b433d1490>
Validation files: <flash.video.classification.input.VideoClassificationCSVInput object at 0x7f1b45e00f50>
/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['metrics'])`.
  rank_zero_warn(
/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'head' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['head'])`.
  rank_zero_warn(
Using 'x3d_m' provided by Facebook Research/PyTorchVideo (https://github.com/facebookresearch/pytorchvideo).
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name          | Type       | Params
---------------------------------------------
0 | train_metrics | ModuleDict | 0     
1 | val_metrics   | ModuleDict | 0     
2 | test_metrics  | ModuleDict | 0     
3 | backbone      | Net        | 3.8 M 
4 | head          | Sequential | 2.8 K 
---------------------------------------------
34.2 K    Trainable params
3.8 M     Non-trainable params
3.8 M     Total params
15.188    Total estimated model params size (MB)
2024-09-16 12:04:37.392383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-16 12:04:39.071245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-16 12:04:39.594093: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-16 12:04:42.255781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-16 12:04:52.041909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Sanity Checking: 0it [00:00, ?it/s]/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Traceback (most recent call last):
  File "/home/olga/Pictures/Rehab-app/multi_upgraded2.py", line 382, in <module>
    trainer.finetune(model, datamodule=datamodule, strategy="freeze")
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/trainer.py", line 164, in finetune
    return super().fit(model, train_dataloader, val_dataloaders, datamodule)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
    self._run_train()
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1204, in _run_train
    self._run_sanity_check()
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1276, in _run_sanity_check
    val_loop.run()
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 152, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 121, in advance
    batch = next(data_fetcher)
            ^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py", line 184, in __next__
    return self.fetching_function()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py", line 275, in fetching_function
    return self.move_to_device(batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py", line 294, in move_to_device
    batch = self.batch_to_device(batch)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 142, in batch_to_device
    batch = self.trainer._call_strategy_hook("batch_to_device", batch, dataloader_idx=dataloader_idx)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 273, in batch_to_device
    return model._apply_batch_transfer_handler(batch, device=device, dataloader_idx=dataloader_idx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 343, in _apply_batch_transfer_handler
    batch = self._call_batch_hook("on_after_batch_transfer", batch, dataloader_idx)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/core/module.py", line 330, in _call_batch_hook
    return trainer_method(hook_name, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1375, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/data/data_module.py", line 390, in on_after_batch_transfer
    batch = transform(batch)
            ^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/data/io/input_transform.py", line 792, in __call__
    transformed_collated_samples = self.per_batch_transform(collated_samples, self.stage)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/data/io/input_transform.py", line 635, in _per_batch_transform_on_device
    return self.current_transform(stage=stage, current_fn="per_batch_transform_on_device")(batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/data/transforms.py", line 85, in forward
    result[keys[0]] = super().forward(inputs[0])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/flash/core/data/utils.py", line 132, in forward
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/home/olga/Pictures/my/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 486, in __call__
    return self.lambd(img)
           ^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/Rehab-app/multi_upgraded2.py", line 151, in <lambda>
    T.Lambda(lambda x: normalize_tensor(x, self.mean, self.std)),
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/olga/Pictures/Rehab-app/multi_upgraded2.py", line 113, in normalize_tensor
    return (tensor - mean[None, None, :, None, None]) / std[None, None, :, None, None]
            ~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RuntimeError: The size of tensor a (8) must match the size of tensor b (3) at non-singleton dimension 2

